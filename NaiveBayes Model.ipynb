{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile NaiveBayes/NaiveBayesModel.py\n",
    "#!/usr/bin/env python\n",
    "from math import log\n",
    "from math import exp\n",
    "\n",
    "class NaiveBayesModel(object):\n",
    "\n",
    "    def __init__(self, modelFile):\n",
    "        self.model = {}\n",
    "        recordStrs = [s.split('\\n')[0].split('\\t') for s in open(modelFile).readlines()]\n",
    "        for word, statsStr in recordStrs:\n",
    "            self.model[word] = map(float, statsStr.split(\",\"))\n",
    "        #Class priors: counts and probs (Pr(Class =0) and Pr(Class =1))\n",
    "        self.c0, self.c1, self.prClass0, self.prClass1 = map(float, self.model[\"ClassPriors\"])\n",
    "\n",
    "    def classify(self, doc):\n",
    "        # Posterior Probabilities Pr(Class=0| Doc) and Pr(Class=1| Doc) \n",
    "        # Naive Bayes inference Pr(Class=0| Doc)  ~ Pr(Class=0) * Pr(Class=0| word1) * Pr(Class=0| word2)...... \n",
    "        PrClass0GivenDoc = self.prClass0  \n",
    "        PrClass1GivenDoc = self.prClass1\n",
    "        for word in doc:\n",
    "            PrClass0GivenDoc *= self.model[word][2]\n",
    "            PrClass1GivenDoc *= self.model[word][3]\n",
    "        return([PrClass0GivenDoc, PrClass1GivenDoc])\n",
    " \n",
    "    # the natural log based version of this \n",
    "    # helps avoid underflow issues\n",
    "    def classifyInLogs(self, doc):       \n",
    "        # Posterior Probabilities Pr(Class=0| Doc) and Pr(Class=1| Doc) \n",
    "        # Naive Bayes inference Pr(Class=0| Doc)  ~ Pr(Class=0) * Pr(Class=0| word1) * Pr(Class=0| word2)...... \n",
    "        PrClass0GivenDoc = log(self.prClass0)  \n",
    "        PrClass1GivenDoc = log(self.prClass1)\n",
    "        for word in doc:  #NOTE: Improvement: on loading one should convert probs to log probs!\n",
    "            c0 = self.model[word][2]\n",
    "            c1 = self.model[word][3]\n",
    "            if c0 != 0:\n",
    "                PrClass0GivenDoc += log(c0)\n",
    "            else:\n",
    "                PrClass0GivenDoc = float(\"-inf\")\n",
    "            if c1 != 0:\n",
    "                PrClass1GivenDoc += log(c1)\n",
    "            else:\n",
    "                PrClass1GivenDoc = float(\"-inf\")\n",
    "                \n",
    "        return([PrClass0GivenDoc, PrClass1GivenDoc])\n",
    "        \n",
    "    def printModel(self):\n",
    "        print \"NaiveBayes Model starts here\\n----------------\"\n",
    "        print \"PRIORS: prClass0=%04.3f, prClass1=%04.3f\" % (self.prClass0, self.prClass1)\n",
    "        for word, stats in self.model.items():\n",
    "            print \"Pr(\",word, \"| Class)\", stats  #Pr(Class=0| Doc)  all stats\n",
    "        print \"NaiveBayes Model ENDS here\\n----------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile NaiveBayes/mapper_classify.py\n",
    "#!/usr/bin/env python\n",
    "from NaiveBayesModel import NaiveBayesModel\n",
    "import sys, re, string\n",
    "from math import exp\n",
    "# Init mapper phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NBModel = NaiveBayesModel(\"NaiveBayes/model1.txt\")     \n",
    "NBModel.printModel()  \n",
    "line = \"D5\t0\tChinese Chinese\tChinese Tokyo Japan\"\n",
    "docID, docClass,text = line.split(\"\\t\",2)   \n",
    "words = text.split()\n",
    "PrClass0GivenDoc, PrClass1GivenDoc = NBModel.classify(words)\n",
    "\n",
    "print \"Pr(Class=0| Doc=%s) is %6.5f\" % (docID, PrClass0GivenDoc)\n",
    "print \"Pr(Class=1| Doc=%s) is %6.5f\" % (docID, PrClass1GivenDoc)\n",
    "\n",
    "PrClass0GivenDoc, PrClass1GivenDoc = NBModel.classifyInLogs(words)\n",
    "\n",
    "print \"Pr(Class=0| Doc=D5) = %6.5f, log(Pr(Class=0| Doc=D5)) = %f\" % (exp(PrClass0GivenDoc), PrClass0GivenDoc)\n",
    "print \"Pr(Class=1| Doc=D5) = %6.5f, log(Pr(Class=1| Doc=D5)) = %f\" % (exp(PrClass1GivenDoc), PrClass1GivenDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile NaiveBayes/mapper_model.py\n",
    "#!/usr/bin/env python\n",
    "import sys, re, string\n",
    "\n",
    "# Init mapper phase \n",
    "# define regex for punctuation removal\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "\n",
    "#set class counter\n",
    "\n",
    "#####################\n",
    "class0_counter = 0\n",
    "class1_counter = 0\n",
    "#####################\n",
    "\n",
    "# inner loop mapper phase: process each record\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    # split the line into words\n",
    "    # use subject and body \n",
    "    \n",
    "   \n",
    "    parts = line.split(\"\\t\")\n",
    "    docID, docClass, title = parts[0:3]\n",
    "    \n",
    "    \n",
    "    #=====update class counters====\n",
    "    \n",
    "    if int(docClass) == 1:\n",
    "        class1_counter +=1\n",
    "    if int(docClass) == 0:\n",
    "        class0_counter +=1\n",
    "    #===end class counter=======\n",
    "    \n",
    "    \n",
    "    #----check if there's a text body\n",
    "    if len(parts) == 4:\n",
    "        body = parts[3]\n",
    "    else:\n",
    "        body = \"\"\n",
    "    \n",
    "    # remove punctuations, only have white-space as delimiter\n",
    "    emailStr = regex.sub(' ', title.lower() + \" \" +body.lower()) #replace each punctuation with a space\n",
    "    emailStr = re.sub( '\\s+', ' ', emailStr )            # replace multiple spaces with a space\n",
    "    # split the line into words\n",
    "    words = emailStr.split()\n",
    "\n",
    "\n",
    "# START STUDENT CODE HW221MAPPER\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "        print \"%s\\t%s\\t%s\" %(docClass,word,1)\n",
    "\n",
    "\n",
    "print \"%s\\t%s\\t%s\" %(0,'ClassPriors',class0_counter)\n",
    "print \"%s\\t%s\\t%s\" %(1,'ClassPriors',class1_counter)\n",
    "# END STUDENT CODE HW221MAPPER   \n",
    "\n",
    "# define regex for punctuation removal\n",
    "\n",
    "# increase counters\n",
    "# write the results to STDOUT (standard output);\n",
    "# what we output here will be the input for the\n",
    "# Reduce step, i.e. the input for reducer.py\n",
    "#\n",
    "# tab-delimited; the trivial word count is 1\n",
    "        \n",
    "# END STUDENT CODE HW231MAPPER_MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile NaiveBayes/reducer_model.py\n",
    "#!/usr/bin/env python\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "# START STUDENT CODE HW231REDUCER_MODEL\n",
    "\n",
    "\n",
    "class0_count = defaultdict(int)\n",
    "class1_count = defaultdict(int)\n",
    "vocab = []\n",
    "for line in sys.stdin:\n",
    "\n",
    "    # split\n",
    "    docClass, word, count = line.split('\\t')\n",
    "    if int(docClass) == 1:\n",
    "        class1_count[word] += int(count)\n",
    "    if int(docClass) == 0:\n",
    "        class0_count[word] += int(count)\n",
    "    if word not in vocab:\n",
    "        vocab.append(word)\n",
    "\n",
    "# print class_priors\n",
    "word = 'ClassPriors'\n",
    "sum_class = class0_count[word] + class1_count[word]\n",
    "Pr_word_ham = class0_count[word]/float(sum_class)\n",
    "Pr_word_spam = class1_count[word]/float(sum_class)\n",
    "\n",
    "\n",
    "\n",
    "print '%s\\t%s,%s,%s,%s' % (word,class0_count[word],class1_count[word],Pr_word_ham,Pr_word_spam)\n",
    "\n",
    "#-------------after print ClassPriors---------#\n",
    "#----delete from the dictionaries and list so they won't affect the count -------#\n",
    "vocab.remove(word)\n",
    "del class0_count[word]\n",
    "del class1_count[word]\n",
    "\n",
    "#--------------end get prior-------------------#\n",
    "        \n",
    "# get total wordcount for each class\n",
    "class0_wc = sum(class0_count.values())\n",
    "class1_wc = sum(class1_count.values())\n",
    "\n",
    "for word in sorted(vocab):\n",
    "    Pr_word_ham = float(class0_count[word])/class0_wc\n",
    "    Pr_word_spam = float(class1_count[word])/class1_wc\n",
    "    print '%s\\t%s,%s,%s,%s' % (word,class0_count[word],class1_count[word],Pr_word_ham,Pr_word_spam)\n",
    "    \n",
    "    \n",
    "# input comes from STDIN\n",
    "\n",
    "# parse the input we got from mapper.py\n",
    "\n",
    "# convert count and spam flag (currently a string) to int\n",
    "\n",
    "\n",
    "# handle msgID - store all IDs as we don't have too much\n",
    "# not the best way to get prior, a two-level MapReduce jobs (ID - word) would be optimal\n",
    "    \n",
    "# calculate NB parameters, and write the dictionary to a file for the classification job\n",
    "# prior probabilities\n",
    "\n",
    "# conditional probability\n",
    "    \n",
    "# END STUDENT CODE HW231REDUCER_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile NaiveBayes/mapper_classify.py\n",
    "#!/usr/bin/env python\n",
    "from NaiveBayesModel import NaiveBayesModel\n",
    "import sys, re, string\n",
    "from math import exp\n",
    "# Init mapper phase \n",
    "\n",
    "# read the MODEL into memory\n",
    "# The model file resides the local disk (make sure to ship it home from HDFS).\n",
    "\n",
    "\n",
    "NBModel = NaiveBayesModel(\"NaiveBayes/model.txt\")  #----added correct way to call module\n",
    "#NBModel.printModel() ### for testing purposes\n",
    "\n",
    "#----uncomment this\n",
    "#NBModel = NaiveBayesModel(\"NaiveBayes.txt\")\n",
    "#----\n",
    "\n",
    "\n",
    "# define regex for punctuation removal\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "# inner loop mapper phase: process each record\n",
    "# input comes from STDIN (standard input)\n",
    "for line in sys.stdin:\n",
    "    # remove leading and trailing whitespace\n",
    "    line = line.strip()\n",
    "    # split the line into words\n",
    "    parts = line.split(\"\\t\")\n",
    "    docID, docClass, title = parts[0:3]\n",
    "    if len(parts) == 4:\n",
    "        body = parts[3]\n",
    "    else:\n",
    "        body = \"\"\n",
    "    # use subject and body \n",
    "    # remove punctuations, only have white-space as delimiter\n",
    "    \n",
    "    ###----Added lower to title\n",
    "    emailStr = regex.sub(' ', title.lower() + \" \" +body.lower()) #replace each punctuation with a space\n",
    "    emailStr = re.sub( '\\s+', ' ', emailStr )            # replace multiple spaces with a space\n",
    "    # split the line into words\n",
    "    words = emailStr.split()\n",
    "\n",
    "# START STUDENT CODE HW231MAPPER_CLASSIFY\n",
    "    PrClass0GivenDoc, PrClass1GivenDoc = NBModel.classifyInLogs(words)\n",
    "    if exp(PrClass1GivenDoc) > exp(PrClass0GivenDoc):\n",
    "        docClassClassify = 1\n",
    "        \n",
    "    else:\n",
    "        docClassClassify = 0\n",
    "        \n",
    "    print '%s\\t%s\\t%s' % (docID,docClass,docClassClassify)\n",
    "    \n",
    "\n",
    "\n",
    "# END STUDENT CODE HW231MAPPER_CLASSIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile NaiveBayes/reducer_classify.py\n",
    "#!/usr/bin/env python\n",
    "from operator import itemgetter\n",
    "import sys, operator, math\n",
    "\n",
    "\n",
    "numberOfRecords = 0\n",
    "NumberOfMisclassifications=0\n",
    "classificationAccurary = 0\n",
    "\n",
    "# START STUDENT CODE HW231REDUCER_CLASSIFY\n",
    "\n",
    "# input comes from STDIN\n",
    "for line in sys.stdin:\n",
    "    \n",
    "\n",
    "    \n",
    "    numberOfRecords += 1\n",
    "    docID,trueLabel,predLabel = line.split('\\t')\n",
    "    if int(trueLabel) != int(predLabel):\n",
    "        NumberOfMisclassifications +=1\n",
    "    \n",
    "classificationAccurary = NumberOfMisclassifications/float(numberOfRecords)\n",
    "\n",
    "# END STUDENT CODE HW231REDUCER_CLASSIFY\n",
    "\n",
    "print 'Multinomial Naive Bayes Classifier Results [number of records, number of missed classified,\\\n",
    " error rate] are \\n %d,%d,%3.2f' % (numberOfRecords, NumberOfMisclassifications, classificationAccurary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
